{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#questions "
      ],
      "metadata": {
        "id": "HnZPElDsoNQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the problem:\n",
        "the problem is how predict the label of the text or post if is fake news or not\n",
        "\n",
        "\n",
        "#What is the input?\n",
        "the input is text that has a about 60000 rows have fake news and right news in addition to some injected noise needed to be cleaned\n",
        "\n",
        "\n",
        "#What is the output?\n",
        "predict the label of the news if they are fake news or True news\n",
        "\n",
        "\n",
        "#What data mining function is required?\n",
        "classification problem\n",
        "\n",
        "\n",
        "#What could be the challenges?\n",
        "the challenges are to get a cleaned text data by Preprocessing techniques in NLP to extract a pure sentence to predict correctly and choose best classifier for this mission.\n",
        "\n",
        "\n",
        "#What is the impact?\n",
        "detect fake news to try to stop spreading it.\n",
        "\n",
        "\n",
        "#What is an ideal solution?\n",
        "getting high accuracy for predict which fake or true news,and which model perfect to train input text (NLP or text classification) in this proplem the best model is logestic regresion according to my trials\n",
        "\n",
        "\n",
        "#What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?\n",
        "\n",
        "1- Character n-grams and word n-grams are two types of language models used in natural language processing applications.\n",
        "In word n-grams, the text is split into sequences of words of length n.\n",
        "In character n-grams, the text is split into sequences of characters of length n.\n",
        "\n",
        "2-On the other hand, word n-grams tend to suffer more from the OOV issue because they rely on exact word matches. If the model encounters a word that it has not seen before, it cannot generate a meaningful representation for it, and the model's performance may suffer as a result.\n",
        "\n",
        "\n",
        "#What is the difference between stop word removal and stemming? Are these techniques language-dependent?\n",
        "\n",
        "1-Stop word removal involves removing common words that don't carry much meaning, such as \"the\", \"a\", \"an\", \"and\", \"is\", \"of\", etc., from the text before further processing. The rationale behind this technique is that these words don't contribute much to the meaning of a sentence and can be safely removed without affecting the overall understanding of the text.\n",
        "on the other hand, stemming, on the other hand, involves reducing words to their base or root form, by removing suffixes and prefixes. For example, the words \"running\", \"runs\", and \"ran\" would all be reduced to \"run\". The aim of stemming is to reduce the dimensionality of the feature space and to group together words that have similar meanings.\n",
        "\n",
        "2-yes, both stop word removal and stemming are language-dependent techniques. Stop words can vary between languages, as different languages have different sets of common words that can be safely removed. Similarly, the rules for stemming can vary between languages, as different languages have different morphological structures.\n",
        "\n",
        "\n",
        "#Is tokenization techniques language dependent? Why?\n",
        "yes,  tokenization techniques are language dependent because they need to take into account the specific rules and patterns of each language to accurately split text into individual tokens. This requires an understanding of the linguistic structure and conventions of each language, and the development of language-specific algorithms and tools to tokenize text effectively.\n",
        "\n",
        "\n",
        "#What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?\n",
        "Count vectorizer creates a matrix where each row represents a document and each column represents a term in the vocabulary. The matrix contains the count of how many times each term appears in each document. this approach doesn't take into account the relative importance of each term within the document or across the corpus. TF-IDF vectorizer, on the other hand, creates a matrix where each row represents a document and each column represents a term in the vocabulary. The matrix contains the TF-IDF score of each term in each document, which is a measure of the term's importance within the document and across the corpus.\n",
        "\n",
        "In terms of selecting n-grams, it is not feasible to use all possible n-grams, especially for larger values of n, as this would result in a very high-dimensional feature space and may lead to overfitting. Instead, a subset of n-grams can be selected based on their frequency and relevance to the task at hand."
      ],
      "metadata": {
        "id": "faPv0fBwoUB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocessing and visualization"
      ],
      "metadata": {
        "id": "UEEtXk35wBlK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "losjlDvYvtaY",
        "outputId": "3525b167-98fa-44cb-a798-fff8f343d9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.7.5)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCCGAfBavtac",
        "outputId": "de024ce1-df41-4133-9994-f0911628cc8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in c:\\programdata\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.23.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.17.0)\n",
            "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, PredefinedSplit\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctLQmZhJvtad",
        "outputId": "5645f00d-4dcd-416f-f23a-47118caf1de0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\LAB\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\LAB\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\LAB\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#download punkt pakages from nltk library\n",
        "nltk.download('punkt')\n",
        "#download stopwords pakages from nltk library\n",
        "nltk.download('stopwords')\n",
        "#download wordnet pakages from nltk library\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6w5nlWOvtad"
      },
      "outputs": [],
      "source": [
        "#read the training data\n",
        "df = pd.read_csv('xy_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH2-fkRTvtad",
        "outputId": "381fca7d-c2f0-42f5-e238-7d04cb49ead3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a hom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                               text  label\n",
              "0  265723  A group of friends began to volunteer at a hom...      0\n",
              "1  284269  British Prime Minister @Theresa_May on Nerve A...      0\n",
              "2  207715  In 1961, Goodyear released a kit that allows P...      0\n",
              "3  551106  Happy Birthday, Bob Barker! The Price Is Right...      0\n",
              "4    8584  Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#display the first five rows \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuoRHzLFvtae",
        "outputId": "c87f2410-afc8-466a-d697-52d2b06e6bcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 3)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#display the dimension of the data\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjfO-8xlvtae",
        "outputId": "9f9dea05-5807-4e1b-a30d-b0457218abe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 3)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#drop duplicates but not found any duplicated rows\n",
        "df = df.drop_duplicates()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJwAveOOvtaf",
        "outputId": "1b7a7104-eaaa-4b7c-a9c8-d04c39212f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id       0\n",
            "text     0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check null values\n",
        "print(df.isna().sum().sort_values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRbU-gYTvtaf"
      },
      "outputs": [],
      "source": [
        "# some simple transformation (always make a copy before assigning)\n",
        "df2 = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1sRBPP5vtaf"
      },
      "outputs": [],
      "source": [
        "#drop id column\n",
        "df = df.drop(['id'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wWahFsXvtag",
        "outputId": "e4c39254-075f-4361-dbbf-1ab4014ce6e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     59645\n",
              "label        3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check number of classes in the label\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWr8jdHbvtag",
        "outputId": "77a0a6d6-d2c7-4846-c0e8-69b58aa5aa20"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#show target classes \n",
        "plt.hist(df['label'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As show in the above figure there are label equal=2 and our label 0 or 1 only so i will drop it "
      ],
      "metadata": {
        "id": "XRtwbAoMF4ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLqJ2j3Ovtag"
      },
      "outputs": [],
      "source": [
        "#removing noisy data (label = 2) at label\n",
        "df = df[(df.label == 0) | (df.label == 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRIsr8TGvtag",
        "outputId": "af491c58-d4d8-4831-ff7f-63da4b1b22ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#check balance of data after drop rows have value 2\n",
        "plt.hist(df['label'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown that the two classes are almost balanced"
      ],
      "metadata": {
        "id": "iwEdq3XKGEy5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CziFwEryvtah",
        "outputId": "70f52826-cdae-4c5b-9c18-e3342a3f0698"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(59768, 2)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check dimension of the data after dropping label 2\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj-ezZ_Bvtah"
      },
      "outputs": [],
      "source": [
        "# call stemmer and stop wrods\n",
        "stemmer = SnowballStemmer(language='english')\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using stemmers and stop words, we can improve the accuracy and efficiency of text analysis algorithms, reduce the dimensionality of the feature space, and make the analysis more robust to variations in the text."
      ],
      "metadata": {
        "id": "hRqGa7JdIMUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**steps to clean the text:**\n",
        "\n",
        "convert all whitespaces (tabs etc.) to single wspace\n",
        "\n",
        "all lowercase\n",
        "\n",
        "remove stopwords, punctuation and stemm\n",
        "\n",
        "Keep only ASCII + European Chars and whitespace, no digits\n",
        "\n",
        "remove any html tags (< /br> often found)"
      ],
      "metadata": {
        "id": "sWOToZuLHScC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxNVYRGPvtah"
      },
      "outputs": [],
      "source": [
        "#define a function to clean the tex\n",
        "def text_clean(text,for_embedding=True):#I will apply embedding \n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)    \n",
        "    text = text.lower()\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:#apply stemmer\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPCIMN5zvtai"
      },
      "outputs": [],
      "source": [
        "#apply the text cleaning function on on the text column\n",
        "df['text'] = df['text'].apply(text_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY_cg0s5vtai",
        "outputId": "c7c60b9b-4b8e-43de-f803-17c3e9f11763"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>group of friends began to volunteer at homeles...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>british prime minister theresa may on nerve at...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in , goodyear released kit that allows ps to b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>happy birthday , bob barker ! the price is rig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>obama to nation innocent cops and unarmed youn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  group of friends began to volunteer at homeles...      0\n",
              "1  british prime minister theresa may on nerve at...      0\n",
              "2  in , goodyear released kit that allows ps to b...      0\n",
              "3  happy birthday , bob barker ! the price is rig...      0\n",
              "4  obama to nation innocent cops and unarmed youn...      0"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print the first five rows after clearning\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axB3961zvtai"
      },
      "outputs": [],
      "source": [
        "#assign the text to X and target label to y\n",
        "X = df['text']\n",
        "y = df['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#first trial"
      ],
      "metadata": {
        "id": "s1h29QqOxWyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZdq2fitvtaj",
        "outputId": "176c0549-468c-469c-eb8e-e51272664cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 73.5min\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed: 80.7min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best_score = 0.8455405578791154\n",
            "Best_params = {'xgb__n_estimators': 800, 'xgb__max_depth': 11, 'xgb__learning_rate': 0.02}\n"
          ]
        }
      ],
      "source": [
        "pipe_xgb =  Pipeline([(\"vectorizer\",TfidfVectorizer(analyzer=\"word\", max_df=0.6, min_df=10, ngram_range=(1, 2))),\n",
        "                      (\"xgb\", XGBClassifier())])\n",
        "params = {\n",
        "          'xgb__n_estimators': [700,800,900],\n",
        "          'xgb__max_depth':[9,10,11],\n",
        "          'xgb__learning_rate' :[0.01,0.02]\n",
        "          }\n",
        "random_search  = RandomizedSearchCV(\n",
        "    pipe_xgb, params, cv=5, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "#fit X and y\n",
        "random_search.fit(X,y)\n",
        "#print best score\n",
        "print(f'Best_score = {random_search.best_score_}')\n",
        "#print best Params\n",
        "print(f'Best_params = {random_search.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observations\n",
        "\n",
        "in this trial I used TFIDF(word), XGBClassifier Model and used random search for tuning hyperparameters and it consumed about one hour and the best were ['model__learning_rate': 0.02, 'model__max_depth': 11, 'model__n_estimators': 800] I used  cross validation set cv=5 it was found that: best score 0.8455\n",
        "score on leaderboard 0.81223 Public"
      ],
      "metadata": {
        "id": "_cjrSAAAY3_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#second trial"
      ],
      "metadata": {
        "id": "0_OTkAGpy6jP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQfIO6eLvtaj",
        "outputId": "d29455df-d310-4d7e-ea84-bc1b04f98a1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done  45 out of  45 | elapsed: 10.7min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best_score = 0.830329379594895\n",
            "Best_params = {'randm_forest__n_estimators': 900, 'randm_forest__max_depth': 30}\n"
          ]
        }
      ],
      "source": [
        "pipe_xgb =  Pipeline([(\"vectorizer\",TfidfVectorizer(analyzer=\"word\", max_df=0.6, min_df=10, ngram_range=(1, 2))),\n",
        "                      (\"randm_forest\", RandomForestClassifier())])\n",
        "params = {\n",
        "          'randm_forest__n_estimators': [700,800,900],\n",
        "          'randm_forest__max_depth':[10,20,30]\n",
        "          }\n",
        "random_search  = RandomizedSearchCV(\n",
        "    pipe_xgb, params, cv=5, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "#fit X and y\n",
        "random_search.fit(X,y)\n",
        "#print best score\n",
        "print(f'Best_score = {random_search.best_score_}')\n",
        "#print best Params\n",
        "print(f'Best_params = {random_search.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observations\n",
        "\n",
        "in this trial I used TFIDF(word), RandomForestClassifier Model and used random search for tuning hyperparameters and it consumed about half hour and the best were ['model__max_depth': 30, 'model__n_estimators': 900] I used cross validation set cv=5 it was found that: best score 0.8303\n",
        "score on leaderboard 0.81988 Public"
      ],
      "metadata": {
        "id": "fCV84jr4aA1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#third trial"
      ],
      "metadata": {
        "id": "vwN1U3FfzC-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3hXajravtaj",
        "outputId": "6bcb7588-bf86-4e59-9991-c4fed7f82260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  1.3min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best_score = 0.8871007259119235\n",
            "Best_params = {'log_reg__solver': 'newton-cg', 'log_reg__penalty': 'l2', 'log_reg__class_weight': 'balanced', 'log_reg__C': 1.6}\n"
          ]
        }
      ],
      "source": [
        "pipe_xgb =  Pipeline([(\"vectorizer\",TfidfVectorizer(analyzer=\"word\", max_df=0.6, min_df=10, ngram_range=(1, 2))),\n",
        "                      (\"log_reg\", LogisticRegression())])\n",
        "params = {\n",
        "          'log_reg__penalty': ['l2'],\n",
        "          'log_reg__C' : [0.6,0.9,1,1.3,1.4,1.6],\n",
        "          'log_reg__class_weight': ['balanced',None],\n",
        "          'log_reg__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "          }\n",
        "random_search  = RandomizedSearchCV(\n",
        "    pipe_xgb, params, cv=5, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "#fit X and y\n",
        "random_search.fit(X,y)\n",
        "#print best score\n",
        "print(f'Best_score = {random_search.best_score_}')\n",
        "#print best Params\n",
        "print(f'Best_params = {random_search.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observations\n",
        "\n",
        "in this trial I used TFIDF(word), LogisticRegression Model and used random search for tuning hyperparameters and it consumed about half hour and the best were ['log_reg__solver': newton-cg, 'log_reg__penalty': 'l2','log_reg__class_weight': 'balanced', 'log_reg__C': 1.6] I used cross validation set cv=5 it was found that: best score 0.8871\n",
        "score on leaderboard 0.86019 Public"
      ],
      "metadata": {
        "id": "PIBxD1vacr8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fourth trial"
      ],
      "metadata": {
        "id": "1uKx1XufzHau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjWgRXJxvtaj",
        "outputId": "d9905780-7d08-437b-d5a0-7fb03085df7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  8.5min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best_score = 0.8871447630883649\n",
            "Best_params = {'log_reg__solver': 'lbfgs', 'log_reg__penalty': 'l2', 'log_reg__C': 1.6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "pipe_xgb =  Pipeline([(\"vectorizer\",TfidfVectorizer(analyzer=\"char\", max_df=0.6, min_df=10, ngram_range=(3, 5))),\n",
        "                      (\"log_reg\", LogisticRegression())])\n",
        "params = {\n",
        "          'log_reg__penalty': ['l2'],\n",
        "          'log_reg__C' : [0.6,0.9,1,1.3,1.4,1.6],\n",
        "          'log_reg__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "          }\n",
        "random_search  = RandomizedSearchCV(\n",
        "    pipe_xgb, params, cv=5, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "#fit X and y\n",
        "random_search.fit(X,y)\n",
        "#print best score\n",
        "print(f'Best_score = {random_search.best_score_}')\n",
        "#print best Params\n",
        "print(f'Best_params = {random_search.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observations\n",
        "\n",
        "in this trial I used TFIDF(character), LogisticRegression Model and used random search for tuning hyperparameters in addition i changed the hyperparameters from the previous trial and it consumed about quarter hour and the best were ['log_reg__solver': Ibfgs, 'log_reg__penalty': 'l2', 'log_reg__C': 1.6] I used cross validation set cv=5 it was found that: best score 0.8871\n",
        "score on leaderboard 0.84794 Public"
      ],
      "metadata": {
        "id": "nu8VOQPSdxUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fifth trial"
      ],
      "metadata": {
        "id": "BoTuZFm0zVB_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcEeqAhavtak"
      },
      "outputs": [],
      "source": [
        "#split the data into train and test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify = y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t09HZUVevtak"
      },
      "outputs": [],
      "source": [
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train (new training set), X\n",
        "split_index = [-1 if x in X_train.index else 0 for x in X.index]\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjpK64G4vtak",
        "outputId": "e041b371-3e86-4678-8be8-3e7027df9b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   15.1s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best_score = 0.8892387717782099\n",
            "Best_params = {'log_reg__solver': 'lbfgs', 'log_reg__penalty': 'l2', 'log_reg__C': 1.4}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "pipe_xgb =  Pipeline([(\"vectorizer\",TfidfVectorizer(analyzer=\"word\", max_df=0.6, min_df=10, ngram_range=(1, 2))),\n",
        "                      (\"log_reg\", LogisticRegression())])\n",
        "params = {\n",
        "          'log_reg__penalty': ['l2'],\n",
        "          'log_reg__C' : [0.5,0.8,1,1.2,1.4],\n",
        "          'log_reg__solver': ['newton-cg', 'lbfgs', 'saga']\n",
        "          }\n",
        "random_search  = RandomizedSearchCV(\n",
        "    pipe_xgb, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "#fit X and y\n",
        "random_search.fit(X,y)\n",
        "#print best score\n",
        "print(f'Best_score = {random_search.best_score_}')\n",
        "#print best Params\n",
        "print(f'Best_params = {random_search.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observations\n",
        "\n",
        "in this trial I used TFIDF(word), LogisticRegression Model and used random search for tuning hyperparameters in addition i changed the hyperparameters from the third trial and it consumed about quarter hour and the best were ['log_reg__solver': Ibfgs, 'log_reg__penalty': 'l2', 'log_reg__C': 1.4] I split the data and used validation set to tune the hyperparameters it was found that: best score 0.8892\n",
        "score on leaderboard 0.86051 Public "
      ],
      "metadata": {
        "id": "qOyXTqxRiek6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#summary\n",
        "\n",
        "in the five trials i used three different model logistic regression, random forest and xgboost, in all trials i used random search to save the time for searsing before using random search i tried grid search and bayesian search with xgboost in the first trial but i had to stop execution because i could not get any result though more than four hours, therefore i decided to use random search ony with different algrithms and hyperparameters.\n",
        "\n",
        "in addition in the first four trials i used cross validation and in the last i used splitted the data and used validation set \n",
        "\n",
        "according to the above trials the best model was logistic regression in three and five it got about 86% on leaderboard"
      ],
      "metadata": {
        "id": "hETQGuzTnppO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-4KI_Z8vtak"
      },
      "outputs": [],
      "source": [
        "data_test = pd.read_csv('x_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38ssdY7gvtak",
        "outputId": "5cf5970c-6b77-450d-d0ea-84b2f37fcaf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(59151, 2)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hY0MyxBvtal"
      },
      "outputs": [],
      "source": [
        "data_test['text'] = data_test['text'].apply(text_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyyLhG-avtal"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_test['id']\n",
        "\n",
        "submission['label'] = random_search.predict_proba(data_test['text'])[:,1]\n",
        "\n",
        "submission.to_csv('sample_submission_walkthrough5.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UEEtXk35wBlK",
        "s1h29QqOxWyZ",
        "0_OTkAGpy6jP",
        "vwN1U3FfzC-X",
        "1uKx1XufzHau",
        "BoTuZFm0zVB_"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}